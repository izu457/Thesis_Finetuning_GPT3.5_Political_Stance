{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from OpenAI Cookbook\n",
    "https://cookbook.openai.com/examples/chat_finetuning_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import json\n",
    "import random\n",
    "import openai\n",
    "import time\n",
    "\n",
    "import helper_functions as fu\n",
    "import cookbook_function as cbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TestKey3'] = 'sk-proj-GL73kbRwhRpgN3EmXz1YT3BlbkFJEMJhTsinxQDel42BZdNz' \n",
    "client = openai.OpenAI(api_key=os.environ['TestKey3'])\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['TestKey3']}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "data/finetuning_data/train_gen.jsonl :\n",
      "Num examples: 13\n",
      "First example:\n",
      "{'role': 'system', 'content': \"Imagine you are an experienced policymaker in the European Parliament. When provided with a legislative proposal supported by either a left- or right-leaning, a general or no majority, your task is to modify the text to potentially gain support from counterfactual majority. Return the revised full text of the proposal with changes highlighted. If the opposing majority would fundamentally reject the proposal based on its topic or core principles, respond with: 'A [left/right] majority would reject the proposal.'\"}\n",
      "{'role': 'user', 'content': 'Supporting majority: None, alter text to: Right majority. Proposal: Listing the third countries whose nationals must be in possession of visas when crossing the external borders and those whose nationals are exempt from that requirement (Kosovo). The proposed Regulation aims to transfer the reference to ‘Kosovo’ from Annex I (list of countries subject to the visa requirement) to Annex II (list of countries exempt from the visa requirement) of Regulation (EU) 2018/1806. As a result, holders of Kosovo biometric passports will benefit from visa-free travel for short stays (i.e. up to 90 days within a period of 180 days) in the EU. Visa liberalisation will take effect on 1 January 2024, in parallel with the launch of the European Travel Information and Authorisation System (ETIAS), which allows the digital processing of information on travellers entering the EU.'}\n",
      "{'role': 'assistant', 'content': 'A right majority would reject the proposal'}\n"
     ]
    }
   ],
   "source": [
    "# read in ft messages for generation task\n",
    "data_paths = [\"data/finetuning_data/train_gen.jsonl\"]\n",
    "\n",
    "# Load the dataset\n",
    "datasets=[]\n",
    "for data_path in data_paths:\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "        print(type(dataset))\n",
    "    datasets.append(dataset)\n",
    "    # Initial dataset stats\n",
    "    print(\"{} :\".format(data_path))\n",
    "    print(\"Num examples:\", len(dataset))\n",
    "    print(\"First example:\")\n",
    "    for message in dataset[0][\"messages\"]:\n",
    "        print(message)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found errors:\n",
      "data_type: 36\n"
     ]
    }
   ],
   "source": [
    "# check for format errors\n",
    "for dataset in data_paths:\n",
    "    cbf.check_format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid jsonl file\n"
     ]
    }
   ],
   "source": [
    "cbf.validate_jsonl('data/finetuning_data/train_gen.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 7, 415\n",
      "mean / median: 171.53846153846155, 160.0\n",
      "p5 / p95: 28.200000000000017, 358.60000000000014\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# check for missing data, distribution of messages in each conversation,\n",
    "# distribution of tokens per conversation, print token limit warnings\n",
    "\n",
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    for ex in dataset:\n",
    "        messages = ex[\"messages\"]\n",
    "        if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "            n_missing_system += 1\n",
    "        if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "            n_missing_user += 1\n",
    "        n_messages.append(len(messages))\n",
    "        convo_lens.append(cbf.num_tokens_from_messages(messages))\n",
    "        assistant_message_lens.append(cbf.num_assistant_tokens_from_messages(messages))\n",
    "        \n",
    "    print(\"Num examples missing system message:\", n_missing_system)\n",
    "    print(\"Num examples missing user message:\", n_missing_user)\n",
    "    cbf.print_distribution(n_messages, \"num_messages_per_example\")\n",
    "    #print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "    cbf.print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "    n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "    print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~17888 tokens that will be charged for during training\n",
      "By default, you'll train for 7 epochs on this dataset\n",
      "By default, you'll be charged for ~125216 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(datasets[0]) # only training data\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload validated files to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded training file id: file-kBl1kDpPtygbfzK9179rVbt0\n"
     ]
    }
   ],
   "source": [
    "# upload validated data file to OpenAI API\n",
    "\n",
    "train_upload = client.files.create(\n",
    "  file=open(\"data/finetuning_data/train_gen.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    "  )\n",
    "print(\"Uploaded training file id:\", train_upload.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Fine-Tuning Job via OpenAI Software Development Kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-BnUPm66GFpZ6JgBlboaJX7dp \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-BnUPm66GFpZ6JgBlboaJX7dp', created_at=1722085202, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-3.5-turbo-0125:lse:mig-gen:9pbPAZan', finished_at=1722085538, hyperparameters=Hyperparameters(n_epochs=5, batch_size=1, learning_rate_multiplier=2.0), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-URxBkHYInUDxHdJfjeVT2W58', result_files=['file-eXLrVS0234yUcoBMtQiqSqXD'], seed=124, status='succeeded', trained_tokens=89310, training_file='file-hzYyqN63Wsz9Zt4mACOX1FZ0', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='mig_gen')\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "test1 = client.fine_tuning.jobs.retrieve(\"ftjob-BnUPm66GFpZ6JgBlboaJX7dp\")\n",
    "print(test1)\n",
    "print(test1.hyperparameters.n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 combinations in total\n",
      "[(2, 5, 1), (2, 5, 2), (2, 7, 1), (2, 7, 2), (2, 10, 1), (2, 10, 2), (5, 5, 1), (5, 5, 2), (5, 7, 1), (5, 7, 2), (5, 10, 1), (5, 10, 2), (10, 5, 1), (10, 5, 2), (10, 7, 1), (10, 7, 2), (10, 10, 1), (10, 10, 2)]\n",
      "Processing hyperparameters (lr=2, epoch=5, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-HCLyCTqZ7mZjwgEkEnXUtZpo\n",
      "Processing hyperparameters (lr=2, epoch=5, batch=2)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.795325 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.614474 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.06 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=5, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.849818 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.713820 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2.79 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=5, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.872751 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.849779 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-xdXogKpinn4WiE6iTUZhWMhV\n",
      "Processing hyperparameters (lr=2, epoch=7, batch=1)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.831668 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.622463 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.92 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.983177 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.743003 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2.93 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.986262 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.681078 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4.81 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.903644 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.868611 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8.29 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.878240 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.516926 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16.56 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.889412 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.764873 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.13 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hyperparameters (lr=2, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.949075 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.807965 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2.29 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing hyperparameters (lr=2, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.996266 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.685970 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4.95 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.955661 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.512815 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8.58 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.809574 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.703940 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16.33 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.873943 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.951596 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.49 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.812983 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.524491 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2.70 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.844718 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.638841 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4.14 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.815840 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.748543 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8.83 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-O3ut4OV4mPICkW7Qo6ZMVbGr\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=2)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.819653 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.925444 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.82 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.786939 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.705624 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2.15 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.801205 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.515753 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4.79 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.974257 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.925255 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8.24 seconds...\n",
      "Processing hyperparameters (lr=2, epoch=10, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.902286 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-ON0wLwTjI2SjVZQDignioYzF\n",
      "Processing hyperparameters (lr=5, epoch=5, batch=1)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-3JKYeNtI51VsKsFkkiLR7GA4\n",
      "Processing hyperparameters (lr=5, epoch=5, batch=2)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-nyUJ4ecGqsEbu4M6d5EyTaxE\n",
      "Processing hyperparameters (lr=5, epoch=7, batch=1)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.872933 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.930714 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.71 seconds...\n",
      "Processing hyperparameters (lr=5, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.971169 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.805145 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Connection error.\n",
      "Processing hyperparameters (lr=5, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-NY5KTAow7jK2cg5D0If3rAGm\n",
      "Processing hyperparameters (lr=5, epoch=10, batch=1)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-bzOfgwk5V3K8irNhnufIKpAF\n",
      "Processing hyperparameters (lr=5, epoch=10, batch=2)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-aGlS8HfT7wmQmv2OXQVC5dvU\n",
      "Processing hyperparameters (lr=10, epoch=5, batch=1)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-rfQsJ2Grl2fvbouTYTeKELTM\n",
      "Processing hyperparameters (lr=10, epoch=5, batch=2)\n",
      "Rate limiting: Sleeping for 30.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.794952 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.629994 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.70 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=5, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.870958 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.510356 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2.21 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=5, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.836638 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.987924 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4.47 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=5, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.861121 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.722692 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8.25 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=5, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.947620 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.745004 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16.64 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.830541 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.640347 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.34 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.889163 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.754498 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2.47 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.856528 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.929717 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4.75 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.893899 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.969302 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8.14 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.849192 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.929166 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16.53 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.985378 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.937072 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.90 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.978142 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.605556 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2.12 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.771459 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.930214 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4.59 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.829855 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.909898 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8.57 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=7, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.775841 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.573490 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16.96 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=10, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.981129 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.910365 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1.03 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=10, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.984704 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.885214 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2.78 seconds...\n",
      "Processing hyperparameters (lr=10, epoch=10, batch=1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.922980 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.992440 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Request timed out.\n",
      "Processing hyperparameters (lr=10, epoch=10, batch=2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job created with ID ftjob-ybidDEBWMktMLknd9MZAJ4kn\n",
      "All jobs processed.\n",
      "FineTuningJob(id='ftjob-ybidDEBWMktMLknd9MZAJ4kn', created_at=1722163006, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=10, batch_size=2, learning_rate_multiplier=10.0), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-URxBkHYInUDxHdJfjeVT2W58', result_files=[], seed=124, status='validating_files', trained_tokens=None, training_file='file-kBl1kDpPtygbfzK9179rVbt0', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix='mig_gen')\n"
     ]
    }
   ],
   "source": [
    "# Process jobs\n",
    "all_job_ids = cbf.process_jobs([2, 5, 10], [5, 7, 10], [1, 2], train_upload, 2)\n",
    "print(all_job_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Metrics / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_job_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract information about the jobs\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mextract_job_info\u001b[49m(all_job_ids)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_job_info' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract information about the jobs\n",
    "all_results = cbf.extract_job_info(all_job_ids)\n",
    "display(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn/events?limit=10&after=ftevent-hdiEvIlmn8gu2hSUwA3ldvqE \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn/events?limit=10&after=ftevent-LWQKifF22NiPi9U9deyje76e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn/events?limit=10&after=ftevent-wm028NRv6OXlSLa8qds4zGFk \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn/events?limit=10&after=ftevent-ruZY5FnQfTUvWHjETNlBHVXR \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn/events?limit=10&after=ftevent-dvU1Ux12l5fesbdP3woLSV05 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn/events?limit=10&after=ftevent-nyREPHr1pPX8zKmgAnzm71gc \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn/events?limit=10&after=ftevent-4WDC88bhyATUzoqB7Tj3c8FB \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ybidDEBWMktMLknd9MZAJ4kn/events?limit=10&after=ftevent-QMRl7epA4twFUoBLwPnWmeHf \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "#one_result = extract_job_info([\"ftjob-ybidDEBWMktMLknd9MZAJ4kn\"])\n",
    "one_event = extract_job_info([\"ftjob-ybidDEBWMktMLknd9MZAJ4kn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ft_results(file_id):\n",
    "    \"\"\"\n",
    "    Given a result files id of a finished fine-tuning job, a request is made to the OpenAI API\n",
    "    to retrieve the content of the file. Content is decoded from Base64 and saved to a \n",
    "    csv file, which can be later loaded as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    headers = {'Authorization': f'Bearer sk-proj-GL73kbRwhRpgN3EmXz1YT3BlbkFJEMJhTsinxQDel42BZdNz'}\n",
    "    try:\n",
    "        response = requests.get(f\"https://api.openai.com/v1/files/{str(file_id)}/content\", headers=headers)\n",
    "        response.raise_for_status()  # Raises HTTPError for bad responses (4xx and 5xx)\n",
    "        logger.info(\"Received response for file content.\")\n",
    "        if response.content:\n",
    "            try:\n",
    "                # Parse the JSON content\n",
    "                decoded_content = base64.b64decode(response.content).decode('utf-8')\n",
    "                decoded_content = fix_base64_padding(decoded_content)\n",
    "                logger.info(\"Parsed JSON content successfully.\")\n",
    "                with open(\"decoded_content.csv\", \"w\") as f:\n",
    "                    f.write(decoded_content)\n",
    "                logger.info(\"File 'decoded_content.csv' written successfully.\")\n",
    "            except (ValueError, base64.binascii.Error) as e:\n",
    "                # Handle the case where the response is not valid JSON\n",
    "                logger.error(\"Response content could not be parsed as JSON\")\n",
    "                logger.error(f\"Exception: {e}\")\n",
    "                logger.error(response.content)\n",
    "        else:\n",
    "            logger.error(\"Response content is empty\")\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        logger.error(f\"HTTP error occurred: {http_err}\")\n",
    "    except requests.exceptions.RequestException as err:\n",
    "        logger.error(f\"Error occurred: {err}\")\n",
    "    return \"decoded_content.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>learning_rate_multiplier</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>status</th>\n",
       "      <th>event_ids</th>\n",
       "      <th>result_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ftjob-ybidDEBWMktMLknd9MZAJ4kn</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-HWjLZACgNA6rW1aIfFkYRlLg, ftevent-pcV...</td>\n",
       "      <td>[file-LT0GFbSE6cF3vBuCctGiQm4K]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_id  learning_rate_multiplier  n_epochs  \\\n",
       "0  ftjob-ybidDEBWMktMLknd9MZAJ4kn                      10.0        10   \n",
       "\n",
       "   batch_size     status                                          event_ids  \\\n",
       "0           2  succeeded  [ftevent-HWjLZACgNA6rW1aIfFkYRlLg, ftevent-pcV...   \n",
       "\n",
       "                  result_file_name  \n",
       "0  [file-LT0GFbSE6cF3vBuCctGiQm4K]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-LT0GFbSE6cF3vBuCctGiQm4K'%5D/content\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'decoded_content.csv'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#display(one_result)\n",
    "display(one_event)\n",
    "cbf.get_ft_results(one_event.loc[0, \"result_file_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# concatenate all results files to one dataframe\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(all_results)):\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# get job_id\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     job_id \u001b[38;5;241m=\u001b[39m \u001b[43mall_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjob_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(job_id)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# get result_files\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "# go through column \"result_file_name\" of dataframe all_results and get the content \n",
    "# of the result files\n",
    "# als neue Spalte in all_results_df einfügen\n",
    "# get the metrics and checkpoints data for each job\n",
    "\n",
    "for i, (job_id, result_file_name) in enumerate(zip(all_results.job_id, all_results.result_file_name)):\n",
    "    metrics_df = pd.read_csv(cbf.get_ft_results(result_file_name))\n",
    "    # add metrics_df to an overall df\n",
    "    if i == 0:\n",
    "        all_metrics_df = metrics_df\n",
    "    else:\n",
    "        all_metrics_df = pd.concat([all_metrics_df, metrics_df], axis=0)\n",
    "    checkpoints_df = cbf.get_checkpoint_results(job_id)\n",
    "    # add checkpoints_df to a overall df\n",
    "    if i == 0:\n",
    "        all_checkpoints_df = checkpoints_df\n",
    "    else:\n",
    "        all_checkpoints_df = pd.concat([all_checkpoints_df, checkpoints_df], axis=0)\n",
    "\n",
    "display(all_metrics_df.head())\n",
    "display(all_checkpoints_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
