{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from OpenAI Cookbook\n",
    "https://cookbook.openai.com/examples/chat_finetuning_data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "import json\n",
    "import random\n",
    "import openai\n",
    "import time\n",
    "\n",
    "import helper_functions as fu\n",
    "import cookbook_function as cbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TestKey3'] = 'sk-proj-GL73kbRwhRpgN3EmXz1YT3BlbkFJEMJhTsinxQDel42BZdNz' \n",
    "client = openai.OpenAI(api_key=os.environ['TestKey3'])\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {os.environ['TestKey3']}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid jsonl file\n",
      "<class 'list'>\n",
      "data/finetuning_data/train_gen.jsonl :\n",
      "Num examples: 20\n",
      "First example:\n",
      "{'role': 'system', 'content': \"Imagine you are an experienced policymaker in the European Parliament. When provided with a legislative proposal supported by either a left- or right-leaning, a general or no majority, your task is to modify the text to potentially gain support from counterfactual majority. Return the revised full text of the proposal with changes highlighted. If the opposing majority would fundamentally reject the proposal based on its topic or core principles, respond with: 'A [left/right] majority would reject the proposal.'\"}\n",
      "{'role': 'user', 'content': 'Supporting majority: None, alter text to: Right majority. Proposal: Listing the third countries whose nationals must be in possession of visas when crossing the external borders and those whose nationals are exempt from that requirement (Kosovo). The proposed Regulation aims to transfer the reference to ‘Kosovo’ from Annex I (list of countries subject to the visa requirement) to Annex II (list of countries exempt from the visa requirement) of Regulation (EU) 2018/1806. As a result, holders of Kosovo biometric passports will benefit from visa-free travel for short stays (i.e. up to 90 days within a period of 180 days) in the EU. Visa liberalisation will take effect on 1 January 2024, in parallel with the launch of the European Travel Information and Authorisation System (ETIAS), which allows the digital processing of information on travellers entering the EU.'}\n",
      "{'role': 'assistant', 'content': 'A right majority would reject the proposal'}\n",
      "Valid jsonl file\n",
      "<class 'list'>\n",
      "data/finetuning_data/val_gen.jsonl :\n",
      "Num examples: 4\n",
      "First example:\n",
      "{'role': 'system', 'content': \"Imagine you are an experienced policymaker in the European Parliament. When provided with a legislative proposal supported by either a left- or right-leaning, a general or no majority, your task is to modify the text to potentially gain support from counterfactual majority. Return the revised full text of the proposal with changes highlighted. If the opposing majority would fundamentally reject the proposal based on its topic or core principles, respond with: 'A [left/right] majority would reject the proposal.'\"}\n",
      "{'role': 'user', 'content': \"Supporting majority: Left, alter text to: right majority. Proposal: Asylum and Migration Fund. PURPOSE: to establish the asylum and migration fund for the period 2021-2027. PROPOSED ACT: Regulation of the European Parliament and of the Council. ROLE OF THE EUROPEAN PARLIAMENT: the European Parliament decides in accordance with the ordinary legislative procedure and on an equal footing with the Council. BACKGROUND: during the refugee crisis of 2015 and 2016, the EU budget has played a decisive role in managing flows of asylum seekers and migrants. The European migration agenda adopted in May 2015 stressed the need for a consistent common policy to restore confidence in the Union’s ability to combine European and national efforts to address migration issues. In October 2017, the European Council reaffirmed the need for a comprehensive approach to managing migration flows, aimed at restoring control of external borders and reducing irregular arrivals and deaths at sea. Drawing on the lessons from the past, the Commission, in its proposal for the multiannual financial framework for the period 2021-2027, proposed to significantly increase the share of the overall EU budget devoted to migration and external border management by more than 2.6 times, including an increase in the funding allocated to decentralised bodies in this policy area. The renewed Asylum and Migration Fund (AMF) shall build on the results and investments made with the support of previous funds: the European Refugee Fund, the European Fund for the Integration of Third Country Nationals, the European Return Fund, and the Asylum, Migration and Integration Fund (AMIF) for the period 2014-2020. CONTENT: the proposal for a Regulation - presented for a Union of 27 Member States - seeks to establish the asylum and migration fund for the period 2021-2027. Its scope is largely inspired by the current AMIF Regulation, while taking into account new strategic developments and the mandates of the European Border and Coast Guard Agency and the future European Union Agency for Asylum. The Fund shall continue to support the EU's overall policies in the field of migration, integration and return, such as support to: - strengthen and develop the Common European Asylum System (including its external dimension); - promote solidarity and shared responsibility between Member States, in particular towards those States most affected by flows of migrants and asylum seekers; - support legal migration to Member States and encourage the development of immigration strategies that respect the integration process of third-country nationals; - support capacity building in Member States and promote fair and effective return strategies as well as the development of partnerships and cooperation with third countries. Support to Member States: in addition to a basic amount of EUR 5 million allocated to Member States at the beginning of the programming period, the financial envelope foreseen for the programmes of Member States shall be allocated based on a distribution key reflecting the needs and pressures experienced by Member States in the area of integration. It is proposed to give 30% weighting to the area of asylum, 30% to the area of legal migration and integration and 40% to the area of countering irregular migration including returns. The Commission shall carry out a mid-term and a retrospective evaluation of this Regulation, including the actions implemented under the fund. A mid-term review shall take into account new or additional pressures. The remaining 40 % should be managed through a thematic facility, which shall periodically provide funding for the support for specific actions, providing additional funding for dedicated actions of high EU added value. Specific attention shall be put on promoting effective returns; support for resettlement and the solidarity and responsibility efforts between the Member States. Proposed budget: the financial envelope for the implementation of the fund for the period 2021-2027 shall be EUR 10.41 billion in current prices. The financial resources shall be used as follows: - EUR 6.24 billion for actions in support of Member States in migration management programmes implemented under shared management; - EUR 4.16 billion for the thematic mechanism for specific actions to Member States, projects with a European dimension, and to address urgent needs. It should be noted that the Commission proposal concerning the multiannual financial framework provides for EUR 865 million (in current prices) to the relevant decentralised agencies for the period 2021-2027\"}\n",
      "{'role': 'assistant', 'content': \"A [right] majority would propose to change the part 'to support legal migration to the Member States including to contribute to the integration of third-country nationals;' to 'to support legal Immigration policies on the national level in accordance with Member States’ economic needs'\"}\n",
      "Valid jsonl file\n",
      "<class 'list'>\n",
      "data/finetuning_data/test_gen.jsonl :\n",
      "Num examples: 5\n",
      "First example:\n",
      "{'role': 'system', 'content': \"Imagine you are an experienced policymaker in the European Parliament. When provided with a legislative proposal supported by either a left- or right-leaning, a general or no majority, your task is to modify the text to potentially gain support from counterfactual majority. Return the revised full text of the proposal with changes highlighted. If the opposing majority would fundamentally reject the proposal based on its topic or core principles, respond with: 'A [left/right] majority would reject the proposal.'\"}\n",
      "{'role': 'user', 'content': \"Supporting majority: General/Left, alter text to: right majority.  Proposal: European network of Employment Services, workers' access to mobility services and the further integration of labour markets PURPOSE: to reinforce the EURES network with the aim of enhancing access of workers to intra-EU labour mobility support services, thus supporting fair mobility and increasing access to employment opportunities throughout the Union. PROPOSED ACT: Regulation of the European Parliament and of the Council. ROLE OF THE EUROPEAN PARLIAMENT: the European Parliament decides in accordance with the ordinary legislative procedure and on an equal footing with the Council. BACKGROUND: the free movement of workers is a fundamental freedom of Union citizens and one of the pillars of the internal market in the Union enshrined in Article 45 of the TFEU.  Article 46 sets out the measures to bring about this freedom, in particular by ensuring close cooperation between the Public Employment Services ('PES'). The free movement of workers is a key element to the development of a more integrated Union labour market which allows worker mobility from high unemployment areas to areas characterised by labour shortages. It also contributes to finding the right skills for vacant positions and overcoming bottlenecks in the labour market.  Only approximately 7.5 million of the European labour force of around 241 million (i.e. 3.1%) is economically active in another Member State. At present, high unemployment rates in some Member States coexist with high numbers of open job vacancies in others. There are many reasons why the potential for intra-EU labour mobility remains untapped and individual citizens do not realise their intentions to become mobile workers. The most common practical difficulties expected or encountered are the lack of relevant language knowledge and the difficulties in finding a job. The EU can contribute to addressing the latter by raising awareness on employment opportunities across the Union and developing appropriate support services to encourage intra-EU recruitments. The provisions of Regulation 492/2011 of the Euro pean Parliament and of the Council on freedom of movement for workers within the Union (codification) established mechanisms for clearance and for information exchange and the Commission Implementing Decision 2012/733/EU has laid down provisions on the functioning of a network entitled EURES (European Employment Services) in accordance with that Regulation. Whereas the functioning of the EURES network was subject to some changes at the initiative of the Commission through its 2012 Decision, the Chapter II of Regulation 492/2011 which constitutes the European regulatory framework for the clearance and information exchange between Member States on intra-EU labour mobility has not been amended since 1992. This regulatory framework needs to be revised to reflect new mobility patterns, enhanced requirements for fair mobility, changes in the technology for sharing job vacancy data, the use of a variety of recruitment channels by job seekers and employers and the increasing role of other labour market brokers next to the Public Employment Services ('PES') in the provision of recruitment services. A common framework for cooperation should be established between Member States and the Commission on labour mobility within the Union. This framework should bring together job vacancies from across the Union and the possibility of applying for those job vacancies ('clearance'), define the provision of related support services to workers and employers and provide for a common approach to share information necessary to facilitate said co-operation. IMPACT ASSESSMENT: the Commission conducted an impact assessment of policy alternatives to address shortcomings: - Option 1: no new options, - Option 2: amending Regulation 492/2011 as regards the powers of the Commission on the implementation of its provisions (Lisbonisation), - Option 3: introducing a new Regulation with new provisions altogether (modernisation of EURES)  , - Option 4: introducing a new Regulation with a specific Commission mandate to increase the co-operation between public and private employment services. Option 3 is the preferred option which should replace Regulation 492/2011 and the 2012 Decision with a stand-alone instrument combining the provisions of the two instruments. Within this option, a number of specific alternatives were discarded as not being proportionate to the specific objectives. LEGAL BASIS: Article 46 of the Treaty on the Functioning of the European Union (TFEU). CONTENT: the aim of this proposal is to enhance access of workers to intra-EU labour mobility support services, thus supporting fair mobility and increasing access to employment opportunities throughout the Union. It replaces the provisions on the exchange of information on job vacancies, job applications and CV’s across Member States (“clearance”) found currently in Regulation 492/2011.  It also (re)establishes the European network of Employment Services, called EURES, the purpose of which will be to provide assistance with job search and recruitment across Member States. A similar network is active today on the basis of the 2012 Commission Decision. Therefore, upon adoption of this Regulation, the Commission will repeal the above Decision on the functioning of the current EURES network. In this context, the Commission recently introduced a proposal to establish a network of PES to deepen cooperation and mutual learning. That network will cover a wider range of objectives and initiatives in the form of incentives and is complementary to this proposal. Objectives: the general objective is to make the EURES network an effective instrument for any job seeker or employer interested in intra-EU labour mobility. Shortcomings have been identified in the functioning of the EURES network (such as an incomplete pool of job vacancies and CVs; limited automated matching potential; insufficient support services and cross-border information on labour). The specific objectives of the proposal address these shortcomings: - to achieve on the EURES portal a nearly complete supply of job vacancies, with job seekers all over Europe having instant access to the same vacancies, in combination with an extensive pool of CV’s available from which registered employers can recruit; - to enable the EURES portal to carry out a good automated matching between job vacancies and CV’s across Member States, translating in all EU languages and understanding skills, competences, qualifications and occupations acquired at national and sectoral level; - to make available basic information about the EURES network throughout the Union to any job seeker or employer seeking client services for recruitment and to consistently offer any person interested access to the EURES network; - to assist any such person interested with matching, placement and recruitment through the EURES network; - to support the functioning of the EURES network through information exchange on national labour shortages and surpluses and the coordination of actions across Member States. More specifically, the proposal seeks to: - integrate into a single framework the provisions of chapter II and Article 38 of Regulation 492/2011 and the Commission Decision 733/2012/EU on the EURES network. There may also be a possibility to extend the scope of the EURES network to cover apprenticeships and traineeships; - re-establish the EURES network as well as laying down the new terms and conditions as regards its composition and membership. A single governance body to facilitate practical co-operation between Commission and Member States for this Regulation shall be set up; - introduce specific measures on transparency and automated matching; - introduce the specific measures on mainstreaming and support services. The proposal explicitly supports the extension of the delivery of support services by organisations other than the PES, in principle through the voluntary participation in the EURES network by EURES Partners. In addition, PES are encouraged to develop partnerships to promote a coherent service package to employers as regards intra-EU labour mobility. One specific form of these support structures are cross-border partnerships; - reinforce the existing arrangements for sharing information in the EURES network where it benefits the quality of concrete collective outputs or the coordination of policies of Member States. BUDGETARY IMPLICATIONS: the proposal will not result in any specific budgetary impact for the EU budget. Any activities to be carried out by the European Commission for the EURES network which will result in the need for human and/or financial resources fall under the scope of the Regulation establishing the Programme for Employment and Social Innovation ('EaSI') (2014-2020) and will be covered within the annual budgetary allocation of this programme. For the period 2014-2020, this EU programme will pay for horizontal measures such as the EURES portal, the common training programme, targeted mobility schemes like Your first EURES Job and the development of the European classification for skills/competences, qualifications and occupations (ESCO). For the same period, activities in Member States on intra-EU labour mobility are eligible under the European Social Fund. DELEGATED ACTS: the proposal contains provisions empowering the Commission to adopt delegated acts in accordance with Article 290 of the Treaty on the Functioning of the European Union\"}\n",
      "{'role': 'assistant', 'content': \"A [right] majority would propose to change the part 'To bring offers of employment together with applications for employment each Member State shall make available to the EURES portal:'  to 'offers of employment together with applications for employment each Member State may make available to the EURES portal:'\"}\n"
     ]
    }
   ],
   "source": [
    "# read in ft messages for generation task\n",
    "data_paths = [\"data/finetuning_data/train_gen.jsonl\",\n",
    "              \"data/finetuning_data/val_gen.jsonl\",\n",
    "              \"data/finetuning_data/test_gen.jsonl\"]\n",
    "\n",
    "# Load the dataset\n",
    "datasets=[]\n",
    "for data_path in data_paths:\n",
    "    cbf.validate_jsonl(data_path)\n",
    "    with open(data_path, 'r', encoding='utf-8') as f:\n",
    "        dataset = [json.loads(line) for line in f]\n",
    "        print(type(dataset))\n",
    "    datasets.append(dataset)\n",
    "    # Initial dataset stats\n",
    "    print(\"{} :\".format(data_path))\n",
    "    print(\"Num examples:\", len(dataset))\n",
    "    print(\"First example:\")\n",
    "    for message in dataset[0][\"messages\"]:\n",
    "        print(message)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found errors:\n",
      "data_type: 36\n",
      "Found errors:\n",
      "data_type: 34\n",
      "Found errors:\n",
      "data_type: 35\n"
     ]
    }
   ],
   "source": [
    "# check for format errors\n",
    "for dataset in data_paths:\n",
    "    cbf.check_format(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 0\n",
      "Num examples missing user message: 0\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 3, 3\n",
      "mean / median: 3.0, 3.0\n",
      "p5 / p95: 3.0, 3.0\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 7, 415\n",
      "mean / median: 171.53846153846155, 160.0\n",
      "p5 / p95: 28.200000000000017, 358.60000000000014\n",
      "\n",
      "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# check for missing data, distribution of messages in each conversation,\n",
    "# distribution of tokens per conversation, print token limit warnings\n",
    "\n",
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    for ex in dataset:\n",
    "        messages = ex[\"messages\"]\n",
    "        if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "            n_missing_system += 1\n",
    "        if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "            n_missing_user += 1\n",
    "        n_messages.append(len(messages))\n",
    "        convo_lens.append(cbf.num_tokens_from_messages(messages))\n",
    "        assistant_message_lens.append(cbf.num_assistant_tokens_from_messages(messages))\n",
    "        \n",
    "    print(\"Num examples missing system message:\", n_missing_system)\n",
    "    print(\"Num examples missing user message:\", n_missing_user)\n",
    "    cbf.print_distribution(n_messages, \"num_messages_per_example\")\n",
    "    #print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "    cbf.print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "    n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "    print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~17888 tokens that will be charged for during training\n",
      "By default, you'll train for 7 epochs on this dataset\n",
      "By default, you'll be charged for ~125216 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(datasets[0]) # only training data\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload validated files to OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/files \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded training file id: file-mValQnxzwCVmTUEki1nLSsC9\n"
     ]
    }
   ],
   "source": [
    "# upload validated data file to OpenAI API\n",
    "\n",
    "train_upload = client.files.create(\n",
    "  file=open(\"data/finetuning_data/train_gen.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    "  )\n",
    "print(\"Uploaded training file id:\", train_upload.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Fine-Tuning Jobs via OpenAI Software Development Kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\logging\\__init__.py\", line 1160, in emit\n",
      "    msg = self.format(record)\n",
      "          ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\logging\\__init__.py\", line 999, in format\n",
      "    return fmt.format(record)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\logging\\__init__.py\", line 703, in format\n",
      "    record.message = record.getMessage()\n",
      "                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\logging\\__init__.py\", line 392, in getMessage\n",
      "    msg = msg % self.args\n",
      "          ~~~~^~~~~~~~~~~\n",
      "TypeError: not all arguments converted during string formatting\n",
      "Call stack:\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.1264.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Cäcilia\\AppData\\Local\\Temp\\ipykernel_32908\\4050152956.py\", line 2, in <module>\n",
      "    all_job_ids = cbf.process_jobs([2, 5, 10], [5, 7, 10], [1, 2], train_upload, 1)\n",
      "  File \"c:\\Users\\Cäcilia\\OneDrive\\Dokumente\\_Masterstudium\\Thesis\\Thesis_db\\cookbook_function.py\", line 134, in process_jobs\n",
      "    logger.info(len(combinations), \"hyperparameter combinations in total\")\n",
      "Message: 18\n",
      "Arguments: ('hyperparameter combinations in total',)\n",
      "INFO:cookbook_function:[(2, 5, 1), (2, 5, 2), (2, 7, 1), (2, 7, 2), (2, 10, 1), (2, 10, 2), (5, 5, 1), (5, 5, 2), (5, 7, 1), (5, 7, 2), (5, 10, 1), (5, 10, 2), (10, 5, 1), (10, 5, 2), (10, 7, 1), (10, 7, 2), (10, 10, 1), (10, 10, 2)]\n",
      "INFO:cookbook_function:Standard request interval is set to 60.0 seconds.\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=5, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-O35IDvWOrY2NhtjjbUVgtm7b\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=5, batch=2)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.971675 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-jQMdeA22Wk2ugFuaHpu1zDCv\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=7, batch=1)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-RXmyv4QmzAXytgOaWjbVtqvA\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=7, batch=2)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-ZYUSnKKMURww848wj83Ry7q5\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=10, batch=1)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.969691 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.676396 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 1.14 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.874679 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.797144 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 2.99 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.867563 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.917372 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 4.60 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.923580 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.860162 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 8.37 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.967925 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.796605 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 16.40 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=2, epoch=10, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.786108 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.928016 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-CffGWXvqX85pmysROdxFNEnr\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=5, batch=1)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.921253 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.707207 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 1.06 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=5, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.871617 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.606485 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 2.89 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=5, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.899511 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.711849 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 4.56 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=5, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.889697 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.535745 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 8.78 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=5, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.954604 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.637436 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 16.92 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=5, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=7, batch=1)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-U5qpiUGuzkrjLcDGMvpbFOJw\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=7, batch=2)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.960547 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.852920 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 1.44 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=7, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.759865 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.557410 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 2.48 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=7, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.919213 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.703197 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 4.94 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=7, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.970745 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.904811 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 8.98 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=7, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.928944 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.608608 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 16.47 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.788067 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.569061 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 1.44 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.961463 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.943490 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 2.34 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.891971 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.565096 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 4.85 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.858470 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.810057 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 8.60 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-tSFAJExQR6sQLOUmIPHq0P7b\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=5, epoch=10, batch=2)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-ONB7wgME4xcq2WcCvDAo1kg0\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=1)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.962262 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.805257 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 1.79 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.965851 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.876550 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 2.76 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.957038 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.725404 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 4.06 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.835508 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.669211 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 8.13 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.770483 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.904506 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 16.20 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.754752 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.752281 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 1.24 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.811873 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.632447 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 2.00 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.931818 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.536659 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 4.66 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.883106 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.536437 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 8.64 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=5, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.944592 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.983209 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 16.78 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=7, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.813101 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.691609 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 1.25 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=7, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.871261 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.865615 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 2.53 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=7, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.906885 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.906562 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 4.14 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=7, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.893787 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-4i8eGWOFdb03y5vFJyDfxlFG\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=7, batch=2)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.774449 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.778519 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 1.33 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=7, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.876629 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.700898 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 2.15 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=7, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.864115 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.787224 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 4.58 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=7, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.763056 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.699289 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 8.05 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=7, batch=2)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.756769 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.825199 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 16.70 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.772500 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.981260 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 1.79 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.807260 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.649653 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 2.73 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.828164 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.817080 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 4.75 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 0.801132 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "INFO:openai._base_client:Retrying request to /fine_tuning/jobs in 1.615268 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 429 Too Many Requests\"\n",
      "ERROR:cookbook_function:Rate limit exceeded. Retrying in 8.02 seconds...\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=10, batch=1)\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-JdCJKM25NTGnFjGyxi32STkc\n",
      "INFO:cookbook_function:Processing hyperparameters (lr=10, epoch=10, batch=2)\n",
      "INFO:cookbook_function:Rate limiting: Sleeping for 60.00 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/fine_tuning/jobs \"HTTP/1.1 200 OK\"\n",
      "INFO:cookbook_function:Job created with ID ftjob-NYAJ8AHtANHhX7jSQuLl7AT9\n",
      "INFO:cookbook_function:All batches processed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ftjob-O35IDvWOrY2NhtjjbUVgtm7b', 'ftjob-jQMdeA22Wk2ugFuaHpu1zDCv', 'ftjob-RXmyv4QmzAXytgOaWjbVtqvA', 'ftjob-ZYUSnKKMURww848wj83Ry7q5', 'ftjob-CffGWXvqX85pmysROdxFNEnr', 'ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG', 'ftjob-U5qpiUGuzkrjLcDGMvpbFOJw', 'ftjob-tSFAJExQR6sQLOUmIPHq0P7b', 'ftjob-ONB7wgME4xcq2WcCvDAo1kg0', 'ftjob-4i8eGWOFdb03y5vFJyDfxlFG', 'ftjob-JdCJKM25NTGnFjGyxi32STkc', 'ftjob-NYAJ8AHtANHhX7jSQuLl7AT9']\n"
     ]
    }
   ],
   "source": [
    "# Process jobs\n",
    "all_job_ids = cbf.process_jobs([2, 5, 10], [5, 7, 10], [1, 2], train_upload, 1)\n",
    "print(all_job_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Metrics / Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b/events?limit=10&after=ftevent-vG9KlS9Jknmgfa48ekSn96xN \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b/events?limit=10&after=ftevent-JERBbPOolGrm2lvbcJZ3gqAV \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b/events?limit=10&after=ftevent-cg4d7IfoXQm59ZuR8xNIipon \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b/events?limit=10&after=ftevent-ZlG8QBeYpmKt553YGkq2NCf7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b/events?limit=10&after=ftevent-NbHThP2RuS2xfKzLNrAYGtTN \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b/events?limit=10&after=ftevent-F0yIM1lVnGdYBZGtWuhIiNZ7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b/events?limit=10&after=ftevent-tLTbaaGMpCZfMsxDeZh0TE8e \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-O35IDvWOrY2NhtjjbUVgtm7b/events?limit=10&after=ftevent-ttI2rNNlG324W1vhhJkct5KZ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-jQMdeA22Wk2ugFuaHpu1zDCv \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-jQMdeA22Wk2ugFuaHpu1zDCv/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-jQMdeA22Wk2ugFuaHpu1zDCv/events?limit=10&after=ftevent-SoMAUg3k3cCNye4npBQZuh2E \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-jQMdeA22Wk2ugFuaHpu1zDCv/events?limit=10&after=ftevent-Re1Kj0WQ4Xhw3zNCv1K0chRn \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-jQMdeA22Wk2ugFuaHpu1zDCv/events?limit=10&after=ftevent-VDu1Kc170VMHEypUfMuMHBiB \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-jQMdeA22Wk2ugFuaHpu1zDCv/events?limit=10&after=ftevent-pnzLHRROhGI3g2gOEpFFbzo5 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-jQMdeA22Wk2ugFuaHpu1zDCv/events?limit=10&after=ftevent-r7e2iJFMUslLm3EDnfgvVavd \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-GhVAJn9JQmvhIFf6YEUvwNKR \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-qayxgYm63A6Xo7jzAgsDKuVC \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-zQbt4Tfl1rzSEU8TjS7ZABKu \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-w8PN41gRX7jipsdVYQwT8asY \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-8DiZNKwLU1dEq0nkZ9DURdj6 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-gFpRBeq014fakkQD0rERJuSI \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-azOH5aVLdgxIb8iYaQoOQMFO \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-EjlqoN1JaX0n7D61KnB654es \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-4as64hhSjrBCBiLJRF31Wkb5 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-RXmyv4QmzAXytgOaWjbVtqvA/events?limit=10&after=ftevent-zyDXRexRzpGVWNs3KkQ0qu5Y \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ZYUSnKKMURww848wj83Ry7q5 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ZYUSnKKMURww848wj83Ry7q5/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ZYUSnKKMURww848wj83Ry7q5/events?limit=10&after=ftevent-vWWUaq0WWOPK1Og3x7bFUOZK \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ZYUSnKKMURww848wj83Ry7q5/events?limit=10&after=ftevent-FwZYTVERZ9fTPjZ3kkS4jzHh \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ZYUSnKKMURww848wj83Ry7q5/events?limit=10&after=ftevent-p5v5eRQ97tWaOP4DCkLG4QO2 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ZYUSnKKMURww848wj83Ry7q5/events?limit=10&after=ftevent-fbsl7pmmu0AxEVaApwUTeZgH \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ZYUSnKKMURww848wj83Ry7q5/events?limit=10&after=ftevent-Cq6jZxWIXkwD7vFOhdNQcHnb \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ZYUSnKKMURww848wj83Ry7q5/events?limit=10&after=ftevent-DVeUXWvhRWBNQu2GgPIrxs0x \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr/events?limit=10&after=ftevent-CbCcSJO8GudvrYubIiP8z40s \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr/events?limit=10&after=ftevent-dqfgfQNDtsB7LL2erpLUxI1p \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr/events?limit=10&after=ftevent-NKU5SVBoCc1talN4EL701NGC \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr/events?limit=10&after=ftevent-IKm89tRU4boI90VWG0BWNGPB \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr/events?limit=10&after=ftevent-ssxoSniXP7HlugyquJThxwlY \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr/events?limit=10&after=ftevent-puI3ainEI9KPtIUzaWgOo47j \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr/events?limit=10&after=ftevent-ycG974rs2XKKdUtQ8L038y85 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-CffGWXvqX85pmysROdxFNEnr/events?limit=10&after=ftevent-x6voRZ4XNJhGYHqSXZissJPa \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG/events?limit=10&after=ftevent-D1GxgFs0Xc9J76G5z1QDrGo8 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG/events?limit=10&after=ftevent-cLqVjhrDWNVXzwecjaqQmoSl \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG/events?limit=10&after=ftevent-RfP4Zpwi93tWhxnZ4ua1yw79 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG/events?limit=10&after=ftevent-XU7vW6LRyU1H2h5Q9MWTA1xw \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG/events?limit=10&after=ftevent-74zzPdo3ADiIZXDWBoaXyqpI \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-EC4p36EUHd87XqHyP6IzHEEh \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-D8LqTl5oQR7sAQ6H9xgewnWt \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-yr6jjwLlp5hoHbjNaynu9IIY \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-Usu67zDtRsS0cuRTtKg7RLnS \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-F3eTP37GMpFv8GnzuTA9dp4f \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-0eGpWXsJeoEpaW2ty3Ld00Fv \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-xKTIT0vmBMz0ShdSE9KenBQ0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-18d26MR4nFFbGpHrbyfDm2Je \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-IxApyn16qrnH0SSt8QhInWu4 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-U5qpiUGuzkrjLcDGMvpbFOJw/events?limit=10&after=ftevent-0iWM9MksJeNksZk0NVhzuuaR \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-KogHImKcmzZvUkEMRq0I3CGT \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-Fru6mkKtfDkpXDIEcvXRX65o \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-D5k9QEj9lm4U3h9Gq58lfECK \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-afXse1CdNqUcfecRKmKYBERZ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-knAuZoXyQIBc8gA2AWBGn2A6 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-yAkWFWpSGEoHD3yhoZfqxyQu \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-vSumnQ7hGEMmmHMdwt5HuqoS \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-osm3hUYayCIFw0TTPBhGAUrq \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-qzrL5S8WwWvWwFpyWSC8JHKO \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-kl0n5hUPfpZvkRWUcM5B6Yr5 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-denXHdKTzIdDTvYMov1wuq1t \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-75EX7PJpZFcu1Rr0dCMlCC6x \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-TMY22GREJchzuoElYqQLhehp \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-tSFAJExQR6sQLOUmIPHq0P7b/events?limit=10&after=ftevent-7xFxQuDlDBY8eX4riX5b8KP8 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0/events?limit=10&after=ftevent-L1VTqDKt771HIIcQUFFpDfyF \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0/events?limit=10&after=ftevent-ZPZNwodM8qlQg3AtnQ0Ajsvq \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0/events?limit=10&after=ftevent-URMxhiMB2YuA3Y4d62dK9076 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0/events?limit=10&after=ftevent-CkD1ooTjb2gHT5IauxXDzcou \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0/events?limit=10&after=ftevent-5ZCixL0DeOOkvAKvfTZt1gsL \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0/events?limit=10&after=ftevent-8tKYPFQD4l6gYKKYtmIjGhZK \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0/events?limit=10&after=ftevent-kybM8tjNhIgVglo4Tea6c7T1 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-ONB7wgME4xcq2WcCvDAo1kg0/events?limit=10&after=ftevent-reCnO99MyLR0rLZTQcsGRuV7 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-4i8eGWOFdb03y5vFJyDfxlFG \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-4i8eGWOFdb03y5vFJyDfxlFG/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-4i8eGWOFdb03y5vFJyDfxlFG/events?limit=10&after=ftevent-HrxeIwfri8bnTO90q1jojRUl \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-4i8eGWOFdb03y5vFJyDfxlFG/events?limit=10&after=ftevent-AuUSbkz6cZdixf60880A4QxO \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-4i8eGWOFdb03y5vFJyDfxlFG/events?limit=10&after=ftevent-Ytl9hK3PmlbPQc3rX4bi26OZ \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-4i8eGWOFdb03y5vFJyDfxlFG/events?limit=10&after=ftevent-06paknUdoSP8FMG0nOImLLyg \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-4i8eGWOFdb03y5vFJyDfxlFG/events?limit=10&after=ftevent-3slkyDnnb3cvwJPH3Fq3UuOM \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-4i8eGWOFdb03y5vFJyDfxlFG/events?limit=10&after=ftevent-ofRiPTtVeDTlE3aoQcudpdIm \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-JdCJKM25NTGnFjGyxi32STkc \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-JdCJKM25NTGnFjGyxi32STkc/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-JdCJKM25NTGnFjGyxi32STkc/events?limit=10&after=ftevent-DPVjqsMq4Fv3OnYHp7RjStNU \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-NYAJ8AHtANHhX7jSQuLl7AT9 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-NYAJ8AHtANHhX7jSQuLl7AT9/events?limit=10 \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.openai.com/v1/fine_tuning/jobs/ftjob-NYAJ8AHtANHhX7jSQuLl7AT9/events?limit=10&after=ftevent-zV6ZRJnso14PnsyFyEnTDOpj \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>learning_rate_multiplier</th>\n",
       "      <th>n_epochs</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>status</th>\n",
       "      <th>event_ids</th>\n",
       "      <th>result_file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ftjob-O35IDvWOrY2NhtjjbUVgtm7b</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-rS0Rleo57304js0H7l5fKSCh, ftevent-02H...</td>\n",
       "      <td>[file-frvIjPnudXwxIqGic9rcVdej]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ftjob-jQMdeA22Wk2ugFuaHpu1zDCv</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-HVlq8zJGBRHHF05x4SefP1Y3, ftevent-tvA...</td>\n",
       "      <td>[file-8KLa2ki4jtXQjOiy2bwGHRGX]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ftjob-RXmyv4QmzAXytgOaWjbVtqvA</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-Ns27VkNsAL1RvFYYM0zJxd4j, ftevent-BJT...</td>\n",
       "      <td>[file-jdYpdlCqbaWQbqUT8ziyWeRU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ftjob-ZYUSnKKMURww848wj83Ry7q5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-1m1mfx4CSCQg9j1tFQdqjWiu, ftevent-sCX...</td>\n",
       "      <td>[file-N5zK5WCKGJz2RdmVvEtxXBhT]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ftjob-CffGWXvqX85pmysROdxFNEnr</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-ICLfRCycx19TWNpHWNkIbxIf, ftevent-rR8...</td>\n",
       "      <td>[file-6N5HJtkMxu6VM6Xk9vQPkIMJ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-Ix51a5GUyEBIUTiIl27VYLMv, ftevent-fq9...</td>\n",
       "      <td>[file-x8V5rYzfKkFMdw3iQD1s4g6H]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ftjob-U5qpiUGuzkrjLcDGMvpbFOJw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-WOiJZOsFnUxOSfLD4S6GM5eH, ftevent-0vv...</td>\n",
       "      <td>[file-JoiXiPPcuiKDqS3rsfe5knjj]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ftjob-tSFAJExQR6sQLOUmIPHq0P7b</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-EFFvI7GMy5sBpXc3rAQn3vNd, ftevent-S1G...</td>\n",
       "      <td>[file-ZVjWpDCZ4MyDlugZ84cfpl43]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ftjob-ONB7wgME4xcq2WcCvDAo1kg0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>succeeded</td>\n",
       "      <td>[ftevent-eKRKHzZkyUfr37S3QGBfpyHV, ftevent-ZAP...</td>\n",
       "      <td>[file-6TPtYrmhXqARnYh7jAgsKlNU]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ftjob-4i8eGWOFdb03y5vFJyDfxlFG</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>running</td>\n",
       "      <td>[ftevent-K6Id4OpSlLjwNe6OKBiL4wqu, ftevent-xAE...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ftjob-JdCJKM25NTGnFjGyxi32STkc</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>running</td>\n",
       "      <td>[ftevent-3ZaG6Ix864sNCrFWaJ3FuQEs, ftevent-C7K...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ftjob-NYAJ8AHtANHhX7jSQuLl7AT9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>running</td>\n",
       "      <td>[ftevent-0WMGJZsbDESV6dgQoPRT4CoP, ftevent-FGh...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            job_id  learning_rate_multiplier  n_epochs  \\\n",
       "0   ftjob-O35IDvWOrY2NhtjjbUVgtm7b                       2.0         5   \n",
       "1   ftjob-jQMdeA22Wk2ugFuaHpu1zDCv                       2.0         5   \n",
       "2   ftjob-RXmyv4QmzAXytgOaWjbVtqvA                       2.0         7   \n",
       "3   ftjob-ZYUSnKKMURww848wj83Ry7q5                       2.0         7   \n",
       "4   ftjob-CffGWXvqX85pmysROdxFNEnr                       2.0        10   \n",
       "5   ftjob-k8kBOk7P6MAIwA2l3ZlxWsNG                       5.0         5   \n",
       "6   ftjob-U5qpiUGuzkrjLcDGMvpbFOJw                       5.0         7   \n",
       "7   ftjob-tSFAJExQR6sQLOUmIPHq0P7b                       5.0        10   \n",
       "8   ftjob-ONB7wgME4xcq2WcCvDAo1kg0                       5.0        10   \n",
       "9   ftjob-4i8eGWOFdb03y5vFJyDfxlFG                      10.0         7   \n",
       "10  ftjob-JdCJKM25NTGnFjGyxi32STkc                      10.0        10   \n",
       "11  ftjob-NYAJ8AHtANHhX7jSQuLl7AT9                      10.0        10   \n",
       "\n",
       "    batch_size     status                                          event_ids  \\\n",
       "0            1  succeeded  [ftevent-rS0Rleo57304js0H7l5fKSCh, ftevent-02H...   \n",
       "1            2  succeeded  [ftevent-HVlq8zJGBRHHF05x4SefP1Y3, ftevent-tvA...   \n",
       "2            1  succeeded  [ftevent-Ns27VkNsAL1RvFYYM0zJxd4j, ftevent-BJT...   \n",
       "3            2  succeeded  [ftevent-1m1mfx4CSCQg9j1tFQdqjWiu, ftevent-sCX...   \n",
       "4            2  succeeded  [ftevent-ICLfRCycx19TWNpHWNkIbxIf, ftevent-rR8...   \n",
       "5            2  succeeded  [ftevent-Ix51a5GUyEBIUTiIl27VYLMv, ftevent-fq9...   \n",
       "6            1  succeeded  [ftevent-WOiJZOsFnUxOSfLD4S6GM5eH, ftevent-0vv...   \n",
       "7            1  succeeded  [ftevent-EFFvI7GMy5sBpXc3rAQn3vNd, ftevent-S1G...   \n",
       "8            2  succeeded  [ftevent-eKRKHzZkyUfr37S3QGBfpyHV, ftevent-ZAP...   \n",
       "9            1    running  [ftevent-K6Id4OpSlLjwNe6OKBiL4wqu, ftevent-xAE...   \n",
       "10           1    running  [ftevent-3ZaG6Ix864sNCrFWaJ3FuQEs, ftevent-C7K...   \n",
       "11           2    running  [ftevent-0WMGJZsbDESV6dgQoPRT4CoP, ftevent-FGh...   \n",
       "\n",
       "                   result_file_name  \n",
       "0   [file-frvIjPnudXwxIqGic9rcVdej]  \n",
       "1   [file-8KLa2ki4jtXQjOiy2bwGHRGX]  \n",
       "2   [file-jdYpdlCqbaWQbqUT8ziyWeRU]  \n",
       "3   [file-N5zK5WCKGJz2RdmVvEtxXBhT]  \n",
       "4   [file-6N5HJtkMxu6VM6Xk9vQPkIMJ]  \n",
       "5   [file-x8V5rYzfKkFMdw3iQD1s4g6H]  \n",
       "6   [file-JoiXiPPcuiKDqS3rsfe5knjj]  \n",
       "7   [file-ZVjWpDCZ4MyDlugZ84cfpl43]  \n",
       "8   [file-6TPtYrmhXqARnYh7jAgsKlNU]  \n",
       "9                                []  \n",
       "10                               []  \n",
       "11                               []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract information about the jobs\n",
    "all_results = cbf.extract_job_info(all_job_ids)\n",
    "display(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kann weg\n",
    "#one_result = extract_job_info([\"ftjob-ybidDEBWMktMLknd9MZAJ4kn\"])\n",
    "# one_event = cbf.extract_job_info([\"ftjob-ybidDEBWMktMLknd9MZAJ4kn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kann weg\n",
    "# display(one_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kann weg\n",
    "#display(one_event)\n",
    "#result_two = get_ft_results(one_event.loc[0, \"result_file_name\"])\n",
    "# file_id_2 = one_event.at[0, \"result_file_name\"]\n",
    "# file_id_2 = str(file_id_2).strip()\n",
    "# result_three = get_ft_results(file_id_2)\n",
    "# result_three_df = pd.read_csv(result_three)\n",
    "# display(result_three_df)\n",
    "# result_one = get_ft_results(\"file-LT0GFbSE6cF3vBuCctGiQm4K\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-frvIjPnudXwxIqGic9rcVdej'%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-8KLa2ki4jtXQjOiy2bwGHRGX'%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-jdYpdlCqbaWQbqUT8ziyWeRU'%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-N5zK5WCKGJz2RdmVvEtxXBhT'%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-6N5HJtkMxu6VM6Xk9vQPkIMJ'%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-x8V5rYzfKkFMdw3iQD1s4g6H'%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-JoiXiPPcuiKDqS3rsfe5knjj'%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-ZVjWpDCZ4MyDlugZ84cfpl43'%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B'file-6TPtYrmhXqARnYh7jAgsKlNU'%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n",
      "ERROR:cookbook_function:HTTP error occurred: 404 Client Error: Not Found for url: https://api.openai.com/v1/files/%5B%5D/content\n",
      "INFO:cookbook_function:Decoded response content successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_mean_token_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ftjob-O35IDvWOrY2NhtjjbUVgtm7b</th>\n",
       "      <td>1</td>\n",
       "      <td>2.72383</td>\n",
       "      <td>0.44660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftjob-O35IDvWOrY2NhtjjbUVgtm7b</th>\n",
       "      <td>2</td>\n",
       "      <td>1.89613</td>\n",
       "      <td>0.62360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftjob-O35IDvWOrY2NhtjjbUVgtm7b</th>\n",
       "      <td>3</td>\n",
       "      <td>2.13064</td>\n",
       "      <td>0.58929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftjob-O35IDvWOrY2NhtjjbUVgtm7b</th>\n",
       "      <td>4</td>\n",
       "      <td>1.86259</td>\n",
       "      <td>0.60615</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftjob-O35IDvWOrY2NhtjjbUVgtm7b</th>\n",
       "      <td>5</td>\n",
       "      <td>1.78914</td>\n",
       "      <td>0.57143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftjob-NYAJ8AHtANHhX7jSQuLl7AT9</th>\n",
       "      <td>62</td>\n",
       "      <td>0.05830</td>\n",
       "      <td>0.97865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftjob-NYAJ8AHtANHhX7jSQuLl7AT9</th>\n",
       "      <td>63</td>\n",
       "      <td>0.02298</td>\n",
       "      <td>0.98880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftjob-NYAJ8AHtANHhX7jSQuLl7AT9</th>\n",
       "      <td>64</td>\n",
       "      <td>0.16298</td>\n",
       "      <td>0.95238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftjob-NYAJ8AHtANHhX7jSQuLl7AT9</th>\n",
       "      <td>65</td>\n",
       "      <td>0.05035</td>\n",
       "      <td>0.98693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ftjob-NYAJ8AHtANHhX7jSQuLl7AT9</th>\n",
       "      <td>==</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               step  train_loss  train_accuracy  valid_loss  \\\n",
       "job_id                                                                        \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b    1     2.72383         0.44660         NaN   \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b    2     1.89613         0.62360         NaN   \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b    3     2.13064         0.58929         NaN   \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b    4     1.86259         0.60615         NaN   \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b    5     1.78914         0.57143         NaN   \n",
       "...                             ...         ...             ...         ...   \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9   62     0.05830         0.97865         NaN   \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9   63     0.02298         0.98880         NaN   \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9   64     0.16298         0.95238         NaN   \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9   65     0.05035         0.98693         NaN   \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9   ==         NaN             NaN         NaN   \n",
       "\n",
       "                                valid_mean_token_accuracy  \n",
       "job_id                                                     \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b                        NaN  \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b                        NaN  \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b                        NaN  \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b                        NaN  \n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b                        NaN  \n",
       "...                                                   ...  \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9                        NaN  \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9                        NaN  \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9                        NaN  \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9                        NaN  \n",
       "ftjob-NYAJ8AHtANHhX7jSQuLl7AT9                        NaN  \n",
       "\n",
       "[792 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each row in column \"result_file_name\", use the cell value to request\n",
    "# the file from the OpenAI API using the get_ft_results function and save \n",
    "# it in a metrics dataframe \n",
    "metrics = pd.DataFrame()\n",
    "checkpoints = pd.DataFrame()\n",
    "all_metrics = pd.DataFrame()\n",
    "all_checkpoints = pd.DataFrame()\n",
    "for i, row in all_results.iterrows():\n",
    "    file_id = str(row[\"result_file_name\"]).strip()\n",
    "    metrics = pd.read_csv(cbf.get_ft_results(file_id))\n",
    "    # set index to job_id\n",
    "    metrics[\"job_id\"] = row[\"job_id\"]\n",
    "    metrics.set_index(\"job_id\", inplace=True)\n",
    "    all_metrics = pd.concat([all_metrics, metrics], axis=0)\n",
    "    # Get checkpoints of all jobs\n",
    "    checkpoints = cbf.get_checkpoint_results(row[\"job_id\"])\n",
    "    # Add all strings of chackpoints to one\n",
    "    all_checkpoints = all_checkpoints + checkpoints\n",
    "display(all_metrics)\n",
    "print(all_checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "job_id\n",
       "ftjob-O35IDvWOrY2NhtjjbUVgtm7b    0.01833\n",
       "ftjob-jQMdeA22Wk2ugFuaHpu1zDCv    0.01833\n",
       "ftjob-RXmyv4QmzAXytgOaWjbVtqvA    0.01833\n",
       "Name: train_loss, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models Index(['ftjob-O35IDvWOrY2NhtjjbUVgtm7b', 'ftjob-jQMdeA22Wk2ugFuaHpu1zDCv',\n",
      "       'ftjob-RXmyv4QmzAXytgOaWjbVtqvA'],\n",
      "      dtype='object', name='job_id') are the models with the lowest losses of [0.01833 0.01833 0.01833].\n"
     ]
    }
   ],
   "source": [
    "# Find three most minimal losses to choose the best model\n",
    "min_loss = all_metrics[\"train_loss\"].min()\n",
    "min_losses = all_metrics[\"train_loss\"].nsmallest(3)\n",
    "display(min_loss)\n",
    "display(min_losses)\n",
    "print(f\"Models {min_losses.index} are the models with the lowest losses of {min_losses.values}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using fine-tuned model via Playground or via code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"A right majority would propose to add the additional part to Article 7, paragraph 4: 'This shall be done also to fight illegal migration and cross- border criminality, such as smuggling and trafficking in human beings, weapons and drugs; '\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# test_message = []\n",
    "# with open(\"data/finetuning_data/test_gen.jsonl\", \"r\") as f:\n",
    "#     for line in f:\n",
    "#         test_message.append(json.loads(line))\n",
    "\n",
    "headers=  {'Authorization': f'Bearer sk-proj-GL73kbRwhRpgN3EmXz1YT3BlbkFJEMJhTsinxQDel42BZdNz'}\n",
    "\n",
    "# make a request to the new model\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:lse:mig-gen:9qcUWLEC\",\n",
    "  messages = [{\"role\": \"system\", \"content\": \"Imagine you are an experienced policymaker in the European Parliament. When provided with a legislative proposal supported by either a left- or right-leaning, a general or no majority, your task is to modify the text to potentially gain support from counterfactual majority. Return the revised full text of the proposal with changes highlighted. If the opposing majority would fundamentally reject the proposal based on its topic or core principles, respond with: 'A [left/right] majority would reject the proposal.'\"}, \n",
    "              {\"role\": \"user\", \"content\": \"Supporting majority: General, alter text to: right majority.  Proposal: European Border Surveillance System (EUROSUR)  PURPOSE: to establish a European Border Surveillance System (EUROSUR) with the aim of increasing coordination within and between Member States to prevent and tackle serious crime. PROPOSED ACT: Regulation of the European Parliament and of the Council. BACKGROUND: this proposal shall provide for the necessary legal framework to respond to the request of the European Council of 23-24 June 2011 to further develop the European Border Surveillance System (EUROSUR) as a matter of priority in order to become operational by 2013, allowing Member States' authorities carrying out border surveillance activities and the European Agency for the Management of Operational Cooperation at the External Borders of the Member States of the European Union (Frontex), to share operational information and improve cooperation. The aim of EUROSUR is to reinforce the control of the Schengen external borders. EUROSUR will establish a mechanism for Member States' authorities carrying out border surveillance activities to share operational information and to cooperate with each other and with the Agency in order to reduce the loss of lives at sea and the number of irregular immigrants entering the EU undetected, and to increase internal security by preventing cross-border crimes, such as trafficking in human beings and the smuggling of drugs. The works currently carried out for the testing and the gradual establishment of EUROSUR are based on a roadmap presented in a Commission Communication in 2008. IMPACT ASSESSMENT: the Commission has identified four policy options comprising of sub-options: Option 1: fully decentralised - with the support of the National Coordination Centres (NCC); Option 2: partly centralised – for the EUROSUR network; Option 3: fully centralised approach and including a sub-option 'Cooperation with third countries'; Option 4: common applications of surveillance tools at EU level. In line with the impact assessment, the following options would be the preferred ones: with regard to the establishment of NCCs, Option 1.1 is the preferred option, because it does not require Member States to restructure their national administrations and thus could be easily implemented; - following the decentralised approach for setting up EUROSUR, the preferred policy option for the EUROSUR network is Option 2.2; - taking into account the urgent need for enhancing border control in the Mediterranean region, Option 3.2 provides the best answer on how to promote the cooperation with neighbouring third countries. However, the willingness of northern African countries to cooperate is a precondition for the implementation of Option 3.2. - for the common application of surveillance tools, Option 4.2 is the option providing most added value. LEGAL BASIS: Article 77(2)(d) of the Treaty on the Functioning of the European Union (TFEU) according to which the European Parliament and the Council, acting in accordance with the ordinary legislative procedure, shall adopt measures concerning any measure necessary for the gradual establishment of an integrated management system for external borders. CONTENT: this proposal establishes a common framework for the exchange of information and cooperation between Member States and the Agency in order to improve the situational awareness and reaction capability at the external borders of the Member States and of the European Union, the European Border Surveillance System (EUROSUR). The purpose of the legislative proposal is to improve the situational awareness and reaction capability of Member States and the Agency when preventing irregular migration and cross-border crime at the external land and maritime borders. Common framework: a common framework shall be established with clear responsibilities and competencies for the national coordination centres (NCC) for border surveillance in the Member States and the Agency, which form the backbone of EUROSUR. These centres, which shall ensure an effective and efficient management of resources and personnel at national level, and the Agency shall communicate with each other via the communication network, which would allow to exchange both non-classified sensitive as well as classified information. For the exchange of information and cooperation in the field of border surveillance, Member States and the Agency shall use the framework of EUROSUR, consisting of the following components: (i) national coordination centres for border surveillance; (ii) national situational pictures; (iii) communication network; (iv) European situational picture; (v) common pre-frontier intelligence picture; (vi) common application of surveillance tools. The proposal also outlines the objectives of: Situational pictures: the cooperation and information exchange between the national coordination centres and the Agency is done via 'situational pictures', which shall be established at national and European level as well as for the pre-frontier area. These three pictures, of which the two latter shall be managed by the Agency, are structured in a similar way to facilitate the flow of information among them. The situational pictures will as a general rule not involve personal data but rather the exchange of information on incidents and depersonalised objects, such as the detection and tracking of vessels. In exceptional cases personal data may form part of the data shared by Member States with the Agency provided that the conditions of Frontex Regulation are met. To the extent personal data forms part of the national situational picture of neighbouring external border sections, it may be exchanged between neighbouring Member States only, under the conditions set by the horizontal EU legal framework on data protection; Surveillance tools: the Agency shall provide a service for the common application of surveillance tools, taking into account that such a service can be provided more cost-efficiently at European level. Such a service could be implemented with the support of relevant European space programmes, including the operational Global Monitoring for Environment and Security (GMES). The approach chosen in EUROSUR is to make best use of existing information, capabilities and systems available in other EU agencies to the extent possible. For this reason, the Agency would closely cooperate with the EU Satellite Centre, the European Fisheries Control Agency and the European Maritime Safety Agency in providing the service for the common application of surveillance tools as well as with EUROPOL in order to exchange information on cross-border crime. With regard to maritime traffic data to be provided by the SafeSeaNet system under Directive 2002/59/EC, the Commission intends to make an appropriate proposal modifying the Directive in 2013. It is envisaged that the relevant information in SafeSeaNet will also be made available for purposes other than those related to maritime safety, maritime security and marine environment protection and thereby be part of the surveillance tools used in the EUROSUR framework. Reaction capacity: better awareness of what is going on at the external borders is only of limited value if it is not complemented by an improved capability of EU Member States to react to challenges faced at their external borders. For this reason, Member States shall divide their external borders into borders sections, to which – based on risk analysis and the number of incidents occuring – impact levels shall be attributed. Depending on which impact levels have been attributed, the national coordination centres and the Agency shall take counter-measures in order to lower the impact on the border section in question. Cooperation with third countries: exisiting and planned regional networks set up between Member States and neighbouring third countries shall be linked to EUROSUR via the national coordination centres. Implementation: taking into account that Member States and the Agency are already in the process of setting up the different components of EUROSUR at national and European level, EUROSUR should become operational in the second half of 2013. The Joint Research Centre of the European Commission should provide the Agency with technical support on the further technical development of EUROSUR. Monitoring and evaluation: the Agency shall submit a report on the functioning of EUROSUR on 1 October 2015 and every two years thereafter. The Commission shall provide an overall evaluation of EUROSUR to the European Parliament and the Council on 1 October 2016 and every four years thereafter. Fundamental rights and data protection requirements: this proposal was subjected to scrutiny to ensure that its provisions are fully compatible with fundamental rights and notably human dignity, prohibition of torture and inhuman or degrading treatment or punishment, right to liberty and security, right to the protection of personal data, non-refoulement, non-discrimination and rights of the child. Particular attention was paid to Articles 4 and 19(2) of the EU Charter of Fundamental Rights, which prohibit removal of persons to a State where there is a serious risk of death penalty, torture or other inhuman or degrading treatment or punishment. The draft Regulation explicitly prohibits any exchange of information with a third country that could use this information to identify persons or groups of persons who are under a serious risk of being subjected to torture, inhuman and degrading treatment or punishment or any other violation of fundamental rights. It explicitly provides that Member States and the Agency shall give priority to the special needs of children, victims of trafficking, persons in need of urgent medical assistance, persons in need of international protection, persons in distress at sea and other persons in a particularly vulnerable situation. The protection of personal data is also of particular importance as data sharing may include personal data, in which situation the data protection rules apply and must be fully respected. Territorial provisions: this Regulation constitutes a development of provisions of the Schengen acquis, in which the United Kingdom and Ireland are not participating but which applies to 4 associated countries (Norway, Iceland, Switzerland and Liechtenstein).BUDGETARY IMPLICATION: the different components of EUROSUR will be mainly implemented by the Agency and by Member States (shared management) on the basis of the 2008 EUROSUR roadmap:- with regard to setting up the national coordination centres, Member States will be supported by the External Borders Fund in 2012-2013 and the instrument for financial support for external borders and visa as part of the planned Internal Security Fund in 2014-2020;- the Agency will use its own budget to set up the communication network and other horizontal components of EUROSUR, such as the European situational picture and the common pre-frontier intelligence picture, and when necessary this is completed by support under the Internal Security Fund (direct or indirect centralised financial management);- funding provided under the 7th Framework Programme for Research and Development will support the setting up of the envisaged service for the common application of surveillance tools in 2012-2013;- measures in neighbouring third countries will be supported in 2012-2013 by the Thematic Programme for Asylum and Migration, as part of the Development Cooperation Instrument.The impact assessment provides a financial envelope of EUR 338.7 million from 2011 to 2020.\"}\n",
    "              ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0125:lse:mig-gen:9qcUWLEC\",\n",
    "    messages = [{\"role\": \"user\", \"content\": \"What else could a right majority change?\"}\n",
    "              ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='A right majority could potentially change a wide range of policies and laws, depending on the specific priorities and goals of the majority. Some examples of changes that a right majority might seek to make include:\\n\\n1. Tax policy: A right majority could change the tax code to reduce taxes on businesses and high-income individuals, or to simplify the tax system.\\n\\n2. Immigration policy: A right majority could push for stricter immigration laws, increased border security, and a crackdown on illegal immigration.\\n\\n3. Health care: A right majority might seek to repeal or replace the Affordable Care Act (Obamacare) with a more market-based health care system.\\n\\n4. Environmental regulations: A right majority could relax environmental regulations in order to reduce the burden on businesses and increase economic growth.\\n\\n5. Education: A right majority might seek to expand school choice options, reduce federal involvement in education, or promote alternatives to traditional public schools.\\n\\n6. Social issues: A right majority could take action on social issues such as abortion, same-sex marriage, and transgender rights, depending on the priorities of the majority.\\n\\n7. Criminal justice: A right majority could push for tougher sentencing laws, increased funding for law enforcement, and other changes to the criminal justice system.\\n\\nThese are just a few examples of the many different policies and laws that a right majority could potentially change.', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
